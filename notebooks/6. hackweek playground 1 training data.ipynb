{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d809db4d-84d1-4c7c-9800-d4b8c4a7433f",
   "metadata": {},
   "source": [
    "## Training Data Playground for SWE Forecasting\n",
    "\n",
    "Here is our current training data: \n",
    "\n",
    "Download [here](http://geobrain.csiss.gmu.edu/swe_forecasting/final_merged_data_3yrs_cleaned_v3.csv) from GMU server.\n",
    "\n",
    "If want to access the data via AWS, here is its public S3 URI: [s3://geosmart-hackweek/final_merged_data_3yrs_cleaned_v3_public.csv](s3://geosmart-hackweek/final_merged_data_3yrs_cleaned_v3_public.csv)\n",
    "\n",
    "Because the entire western U.S. region is too big for hackweek, we only choose the smaller region near Sienna to make it easier to collect and aggerate all the datasets and make the ML work. \n",
    "\n",
    "The training subset point locations are here: http://geobrain.csiss.gmu.edu/swe_forecasting/final_merged_data_3yrs_cleaned_v3_hackweek_subset.csv\n",
    "The testing (for operational map generation) subset point locations are here:\n",
    "http://geobrain.csiss.gmu.edu/swe_forecasting/testing_all_ready.csv_hackweek_subset.csv\n",
    "\n",
    "The columns are different in the two csvs and here are the name conversion table:\n",
    "\n",
    "'Latitude': 'lat', \n",
    "\n",
    "'Longitude': 'lon',\n",
    "\n",
    "'vpd': 'mean_vapor_pressure_deficit',\n",
    "\n",
    "'vs': 'wind_speed', \n",
    "\n",
    "'pr': 'precipitation_amount', \n",
    "\n",
    "'etr': 'potential_evapotranspiration',\n",
    "\n",
    "'tmmn': 'air_temperature_tmmn',\n",
    "\n",
    "'tmmx': 'air_temperature_tmmx',\n",
    "\n",
    "'rmin': 'relative_humidity_rmin',\n",
    "\n",
    "'rmax': 'relative_humidity_rmax',\n",
    "\n",
    "'AMSR_SWE': 'SWE',\n",
    "\n",
    "'AMSR_Flag': 'Flag',\n",
    "\n",
    "'Elevation': 'elevation',\n",
    "\n",
    "'Slope': 'slope',\n",
    "\n",
    "'Aspect': 'aspect',\n",
    "\n",
    "'Curvature': 'curvature',\n",
    "\n",
    "'Northness': 'northness',\n",
    "\n",
    "'Eastness': 'eastness'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ae26e4-e851-4ac9-8da5-a4a5a440cd31",
   "metadata": {},
   "source": [
    "### Key Issue #1: Sanity Check of the data\n",
    "\n",
    "We have generated the training.csv via a complicated processing pipeline. But we haven't done a sanity check on the data. We don't know much about its correctness, and it is possible we did mess up the coordination system transformation, mismatch of locations, unit conversion, filling value misuse, etc. We desire a comprehensive sanity checks on the training data before we trust it to train our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b5db67-334a-4762-867f-28614714adc7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Key Issue #2: Collecting More Data\n",
    "\n",
    "The AMSR and GridMet correaltion with SNOTEL is very bad (if the sanity checks passed). If that is verified, we have to collect more data, like MODIS, Landsat, Sentinel, and ICESat-2 and any other available operational datasets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382594b0-9508-4491-a336-5c465f2d05ac",
   "metadata": {},
   "source": [
    "### Key Issue #3: Converting Data into Time Series Training Ready\n",
    "\n",
    "It has been clear that using single day-to-day prediction is low efficient. It is almost always better to take all the data values of the past few days/weeks to take into consideration for every prediction. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
